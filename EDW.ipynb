{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly_express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a graph for feature importances\n",
    "def plt_feature_importance():\n",
    "    feature_imp = pd.Series(rfc.feature_importances_,index=feat_col)\n",
    "    feature_imp = (feature_imp*100).sort_values(ascending=False)\n",
    "    fig = px.bar(feature_imp,x=feature_imp.index,y=feature_imp.values,labels={'x':'Features','y':'Importance Percentage %'})\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get accuracy of the predicted test class\n",
    "def get_acc(y_test,prediction):\n",
    "    acc = metrics.accuracy_score(y_test, prediction)\n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data using Min Max values\n",
    "def scale_data(X):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    sc = scaler.fit(X)\n",
    "    X = sc.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot algorithm decision boundaries\n",
    "def plot_boundaries(iris,algo):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from plotly import subplots\n",
    "    X = iris[['SepalWidthCm','PetalLengthCm']]  \n",
    "\n",
    "    y = iris.Species\n",
    "    y = le.fit_transform(iris.Species)\n",
    "    h = .02  # step size in the mesh\n",
    "\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    if algo=='rfst':\n",
    "        trees = RandomForestClassifier(max_depth=5,n_estimators=10,\n",
    "                                       random_state=0)\n",
    "        trees.fit(X, y)\n",
    "\n",
    "        trees_overfit = RandomForestClassifier(max_depth=100, \n",
    "                                               n_estimators=10, \n",
    "                                               random_state=0)\n",
    "        trees_overfit.fit(X, y)\n",
    "        \n",
    "    elif algo=='svm':\n",
    "        trees = LinearSVC(penalty='l2', loss='squared_hinge',\n",
    "                dual=True, tol=0.001, C=1,multi_class='ovr',\n",
    "                fit_intercept=True, intercept_scaling=1, class_weight=None,verbose=0\n",
    "                , random_state=0, max_iter=1000)\n",
    "        trees.fit(X,y)\n",
    "        \n",
    "    else:\n",
    "        trees = DecisionTreeClassifier(random_state=0)\n",
    "        trees.fit(X, y)\n",
    "        \n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h)\n",
    "                         , np.arange(y_min, y_max, h))\n",
    "    y_ = np.arange(y_min, y_max, h)\n",
    "\n",
    "    Z = trees.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)    \n",
    "    \n",
    "    \n",
    "    if algo=='rfst':\n",
    "        fig = subplots.make_subplots(rows=1, cols=2,\n",
    "                                  subplot_titles=(\"Random Forest (Depth = 5)\",\n",
    "                                                  \"Random Forest (Depth = 50)\")\n",
    "                                 )\n",
    "\n",
    "        trace1 = go.Heatmap(x=xx[0], y=y_, z=Z,\n",
    "                          colorscale='Viridis',\n",
    "                          showscale=False)\n",
    "\n",
    "        trace2 = go.Scatter(x=X[:, 0], y=X[:, 1], \n",
    "                            mode='markers',\n",
    "                            showlegend=True,\n",
    "                            marker=dict(size=10,\n",
    "                                        color=y, \n",
    "                                        colorscale='Viridis',\n",
    "                                        line=dict(color='black', width=1))\n",
    "                            )\n",
    "\n",
    "        fig.append_trace(trace1, 1, 1)\n",
    "        fig.append_trace(trace2, 1, 1)\n",
    "        \n",
    "    else:\n",
    "        if algo=='dt':\n",
    "            fig = subplots.make_subplots(rows=1, cols=2,subplot_titles=(\"Decision Tree\",\"\"))\n",
    "        else:\n",
    "            fig = subplots.make_subplots(rows=1, cols=2,subplot_titles=(\"Support vector Machine\",\"\"))\n",
    "            \n",
    "        trace1 = go.Heatmap(x=xx[0], y=y_, z=Z,\n",
    "                          colorscale='Viridis',\n",
    "                          showscale=False)\n",
    "\n",
    "        trace2 = go.Scatter(x=X[:, 0], y=X[:, 1], \n",
    "                            mode='markers',\n",
    "                            showlegend=True,\n",
    "                            marker=dict(size=10,\n",
    "                                        color=y, \n",
    "                                        colorscale='Viridis',\n",
    "                                        line=dict(color='black', width=1))\n",
    "                            )\n",
    "\n",
    "        fig.append_trace(trace1, 1, 1)\n",
    "        fig.append_trace(trace2, 1, 1)\n",
    "\n",
    "    if algo=='rfst':\n",
    "        Z = trees_overfit.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "\n",
    "        trace3 = go.Heatmap(x=xx[0], y=y_, \n",
    "                            z=Z,\n",
    "                            colorscale='Viridis',\n",
    "                            showscale=False)\n",
    "\n",
    "        trace4 = go.Scatter(x=X[:, 0], y=X[:, 1],\n",
    "                            mode='markers',\n",
    "                            showlegend=True,\n",
    "                            marker=dict(size=10,\n",
    "                                        color=y, \n",
    "                                        colorscale='Viridis',\n",
    "                                        line=dict(color='black', width=1))\n",
    "                           )\n",
    "        fig.append_trace(trace3, 1, 2)\n",
    "        fig.append_trace(trace4, 1, 2)\n",
    "\n",
    "    for i in map(str, range(1, 3)):\n",
    "        x = 'xaxis' + i\n",
    "        y = 'yaxis' + i\n",
    "        fig['layout'][x].update(showgrid=False, \n",
    "                                zeroline=False,\n",
    "                                showticklabels=False, \n",
    "                                ticks='', \n",
    "                                autorange=True)\n",
    "        fig['layout'][y].update(showgrid=False, \n",
    "                                zeroline=False,\n",
    "                                showticklabels=False, \n",
    "                                ticks='', \n",
    "                                autorange=True)\n",
    "\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confucion matrices for any given algorithm\n",
    "def confusion_matrix(y_test,prediction,algo,acc):\n",
    "    dtpreds = {'Actual':y_test,'Predicted':prediction}\n",
    "    df = pd.DataFrame(dtpreds, columns=['Actual','Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df['Actual'], df['Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    fig = sn.heatmap(confusion_matrix, annot=True,cbar=False)\n",
    "    if algo=='svm':\n",
    "        plt.title(\"Support Vector Machine with Accuracy=\"+str(acc)+\"%\")\n",
    "    elif algo=='dt':\n",
    "        plt.title(\"Decision Tree with Accuracy=\"+str(acc)+\"%\")\n",
    "    elif algo=='rf':\n",
    "        plt.title(\"Randomn Forest with Accuracy=\"+str(acc)+\"%\")\n",
    "    return fig.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <U>The Iris Flower<U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"irisall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris Flowerhas 3 different species:\n",
    "* Iris-virginica\n",
    "* Iris-versicolor\n",
    "* Iris-setosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find a way to classify these species of the Iris among themselves. We have the data of the physical dimensions of the flower like the length and width of the Sepal(Leaves below the petals) and of the Petals. Using this we need to find which species do they belong.\n",
    "\n",
    "Let's get an insight over the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.sample(frac=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>As we can see in the above table, we have the features of the flower in the four columns after the id and we have the species of the flower that we need to predict.<code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we solve this ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import all the libraries that we might require today solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px\n",
    "import numpy as np\n",
    "from plotly import graph_objects as go\n",
    "import sklearn as skl\n",
    "import plotly.offline as py\n",
    "import seaborn as sn\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and try changing the x, y, z values down below with any of the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.scatter_3d(iris,x='SepalLengthCm',y='SepalWidthCm',z='PetalWidthCm',color='Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <u>Statistical Method<U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets seperate out the labels from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.Species\n",
    "X = iris.drop(columns=['Id','Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, X is the set of features and y is the target variable that we will predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the Data into two parts, two thirds of the data will be used in training and the rest one third for testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate out the different species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor = y_train==\"Iris-versicolor\"\n",
    "setosa = y_train==\"Iris-setosa\"\n",
    "virginica = y_train==\"Iris-virginica\"\n",
    "df_versicolor = X_train[versicolor]\n",
    "df_setosa = X_train[setosa]\n",
    "df_virginica = X_train[virginica]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets us find out the mean and standard deviation of the lengths and widths of petal and sepal of each species of the flower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_setosa.describe().iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_versicolor.describe().iloc[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_virginica.describe().iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above information we set a limit range (generally in mean +- standard-deviation) for the various features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hard boundaries and check for reach data row.\n",
    "statpred = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    if(X_test.PetalWidthCm.iloc[i]<=0.35):\n",
    "        label = \"Iris-setosa\"\n",
    "    elif(X_test.PetalLengthCm.iloc[i]<=4.7 and X_test.PetalWidthCm.iloc[i]<=1.51):\n",
    "        label = \"Iris-versicolor\"\n",
    "    else:\n",
    "        label = \"Iris-virginica\"\n",
    "    statpred.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistical approach. We predict the labels by a simple if else condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "c=0\n",
    "for i in statpred:\n",
    "    if y_test.iloc[j]!=i:\n",
    "        c+=1\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Accuracy of Statistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = pd.DataFrame(data = y_test.reset_index(drop=True))\n",
    "compare['Predicted'] = statpred\n",
    "compare['Correct?'] = compare.Species==compare.Predicted\n",
    "compare.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acur = (150-c)*100/150\n",
    "print(np.round(acur,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we still improve this ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try the Machine Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='machinelearning.png' height=\"50\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply any Machine learning algorithm to our data, we must prepare our data accordingly.\n",
    "\n",
    "For the model to be build, our data must be standardized and normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the labels from string to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(iris.Species)\n",
    "X = iris.drop(columns=['Id','Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see below how the species of the flower are converted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all feature columns being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_col = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data to be in a fixed range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scale_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <U>Train Test Split<U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data in two parts, one would be used to train our model and the other to test our model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <U>Support Vector Machine</U> (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A SVM classifies the data by drawing hyperplanes in the available dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"svm.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge',\n",
    "                dual=True, tol=0.001, C=10,multi_class='ovr',\n",
    "                fit_intercept=True, intercept_scaling=1, class_weight=None,verbose=0\n",
    "                , random_state=0, max_iter=1000)\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accsvm = get_acc(y_test,svmpred)\n",
    "print(accsvm,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmsvm = confusion_matrix(y_test,svmpred,'svm',accsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(iris,'svm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <U>Decision Tree Classification<U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='dt.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree is a Supervised Machine Learning technique where the data is continuously split according to a certain parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "dtmodel = dtc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = dtmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are made in numbers as the species were assigned. But they can be converted back to their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpreds = le.inverse_transform(prediction)\n",
    "display(dtpreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accdt = get_acc(y_test,prediction)\n",
    "print(accdt,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmdt = confusion_matrix(y_test,prediction,\"dt\",accdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5 Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(iris,'dt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <U>Random Forest Classification<U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic1.jpeg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<U><code>The reason for this wonderful effect is that the trees protect each other from their individual errors.<code><U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = rfc.predict(X_test)\n",
    "display(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accrf = get_acc(y_test,preds)\n",
    "print(accrf,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmrf = confusion_matrix(y_test,preds,'rf',accrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5 Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_boundaries(iris,'rfst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. <U>Feature Importances</U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features that have been referred to the most to predict the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt_feature_importance()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. <U>Conclusion</U>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(cmsvm,cmrf,cmdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. <U>Feature adding</U>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add two new features to our dataset. We can calculate the area (length x breadth) of sepal and petal and add them as new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['SepalArea'] = iris['SepalLengthCm']*iris['SepalWidthCm']\n",
    "iris['PetalArea'] = iris['PetalLengthCm']*iris['PetalWidthCm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.sample(frac=0.035)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try running the the models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = le.fit_transform(iris.Species)\n",
    "X = iris.drop(columns=['Id','Species'])\n",
    "feat_col = X.columns\n",
    "X = scale_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train,y_train)\n",
    "new_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmacc = get_acc(y_test,new_svm)\n",
    "print(\"Previous Accuracy: \",accsvm,\"%\")\n",
    "print(\"New Accuracy: \",svmacc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_cmsvm = confusion_matrix(y_test,new_svm,\"svm\",svmacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X_train,y_train)\n",
    "new_dtree = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtacc = get_acc(y_test,new_dtree)\n",
    "print(\"Previous Accuracy: \",accdt,\"%\")\n",
    "print(\"New Accuracy: \",dtacc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cmdt = confusion_matrix(y_test,new_dtree,\"dt\",dtacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "new_rfst = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfacc = get_acc(y_test,new_rfst)\n",
    "print(\"Previous Accuracy: \",accrf,\"%\")\n",
    "print(\"New Accuracy: \",rfacc,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cmrf = confusion_matrix(y_test,new_rfst,\"rf\",rfacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt_feature_importance()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
